{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c73cab36",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'soundfile'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msoundfile\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mespnet2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mespnet2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ASRTask\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'soundfile'"
     ]
    }
   ],
   "source": [
    "import soundfile\n",
    "from espnet2.train.trainer import Trainer\n",
    "from espnet2.tasks.asr import ASRTask\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from espnet2.train.distributed_utils import DistributedOption\n",
    "from espnet2.utils.build_dataclass import build_dataclass\n",
    "from espnet2.torch_utils.device_funcs import to_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d267b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = '/data/anakuzne/espnet/egs2/librispeech_100/asr1/exp/asr_codec_frozen_full_lr2e-3_conv_input_large_batch_warmup15k_from_pretrained_num_enc_layers_1/71epoch.pth'\n",
    "config_path = '/data/anakuzne/espnet/egs2/librispeech_100/asr1/exp/asr_codec_frozen_full_lr2e-3_conv_input_large_batch_warmup15k_from_pretrained_num_enc_layers_1/config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5cc5564",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = ASRTask\n",
    "model_latest, asr_train_args = task.build_model_from_file(\n",
    "            config_path, ckpt_path, \"cuda:7\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8c538db",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Path(config_path).open(\"r\", encoding=\"utf-8\") as f:\n",
    "            args = yaml.safe_load(f)\n",
    "args = argparse.Namespace(**args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1723c3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "distributed_option = build_dataclass(DistributedOption, args)\n",
    "# Setting distributed_option.dist_rank, etc.\n",
    "distributed_option.init_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1d6e0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter_factory = task.build_iter_factory(\n",
    "                    args=args,\n",
    "                    distributed_option=distributed_option,\n",
    "                    mode=\"train\",\n",
    "                )\n",
    "\n",
    "valid_iter_factory = task.build_iter_factory(\n",
    "                    args=args,\n",
    "                    distributed_option=distributed_option,\n",
    "                    mode=\"valid\",\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cbdd7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = train_iter_factory.build_iter(1000)\n",
    "data_loader_valid = valid_iter_factory.build_iter(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf5c1212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "683.8096816976127\n"
     ]
    }
   ],
   "source": [
    "model_latest.eval()\n",
    "avg_train_len = 0\n",
    "for iiter, (utt_id, batch) in enumerate(data_loader):\n",
    "    #batch = to_device(batch, \"cuda:7\")\n",
    "    #print(batch[\"speech\"].shape)\n",
    "    #print(iiter, utt_id, batch)\n",
    "    #retval = model_latest(**batch)\n",
    "    #print(\"Train Loss \", retval[0])\n",
    "    avg_train_len += batch['speech'].shape[1]\n",
    "    \n",
    "print(avg_train_len/len(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51587edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESPnetASRModel(\n",
      "  (specaug): SpecAug(\n",
      "    (time_warp): TimeWarp(window=5, mode=bicubic)\n",
      "    (freq_mask): MaskAlongAxis(mask_width_range=[0, 27], num_mask=2, axis=freq)\n",
      "    (time_mask): MaskAlongAxisVariableMaxWidth(mask_width_ratio_range=[0.0, 0.05], num_mask=5, axis=time)\n",
      "  )\n",
      "  (normalize): UtteranceMVN(norm_means=True, norm_vars=False)\n",
      "  (encoder): ConformerEncoder(\n",
      "    (embed): Conv2dSubsampling(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "        (1): ReLU()\n",
      "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "        (3): ReLU()\n",
      "      )\n",
      "      (out): Sequential(\n",
      "        (0): Linear(in_features=65280, out_features=256, bias=True)\n",
      "        (1): RelPositionalEncoding(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (encoders): MultiSequential(\n",
      "      (0): EncoderLayer(\n",
      "        (self_attn): RelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear_pos): Linear(in_features=256, out_features=256, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)\n",
      "          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (after_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (embed): Sequential(\n",
      "      (0): Embedding(5000, 256)\n",
      "      (1): PositionalEncoding(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (after_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "    (output_layer): Linear(in_features=256, out_features=5000, bias=True)\n",
      "    (decoders): MultiSequential(\n",
      "      (0): DecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (src_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): DecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (src_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): DecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (src_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (criterion_att): LabelSmoothingLoss(\n",
      "    (criterion): KLDivLoss()\n",
      "  )\n",
      "  (ctc): CTC(\n",
      "    (ctc_lo): Linear(in_features=256, out_features=5000, bias=True)\n",
      "    (ctc_loss): CTCLoss()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c1190e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Loss True tensor([614.0464], device='cuda:7') Len  1758\n",
      "Valid Loss True tensor([637.0003], device='cuda:7') Len  1608\n",
      "Valid Loss True tensor([572.8401], device='cuda:7') Len  1507\n",
      "Valid Loss True tensor([460.9959], device='cuda:7') Len  1420\n",
      "Valid Loss True tensor([501.3669], device='cuda:7') Len  1349\n",
      "Valid Loss True tensor([482.5706], device='cuda:7') Len  1240\n",
      "Valid Loss True tensor([450.1767], device='cuda:7') Len  1193\n",
      "Valid Loss True tensor([459.9008], device='cuda:7') Len  1141\n",
      "Valid Loss True tensor([376.3450], device='cuda:7') Len  1070\n",
      "Valid Loss True tensor([391.4791], device='cuda:7') Len  1037\n",
      "Valid Loss True tensor([368.1139], device='cuda:7') Len  1011\n",
      "Valid Loss True tensor([366.3072], device='cuda:7') Len  988\n",
      "Valid Loss True tensor([354.7173], device='cuda:7') Len  956\n",
      "Valid Loss True tensor([325.1338], device='cuda:7') Len  925\n",
      "Valid Loss True tensor([314.3872], device='cuda:7') Len  909\n",
      "Valid Loss True tensor([325.4771], device='cuda:7') Len  890\n",
      "Valid Loss True tensor([306.1699], device='cuda:7') Len  878\n",
      "Valid Loss True tensor([319.5894], device='cuda:7') Len  866\n",
      "Valid Loss True tensor([305.9267], device='cuda:7') Len  845\n",
      "Valid Loss True tensor([326.3660], device='cuda:7') Len  833\n",
      "Valid Loss True tensor([322.2534], device='cuda:7') Len  820\n",
      "Valid Loss True tensor([306.2188], device='cuda:7') Len  803\n",
      "Valid Loss True tensor([296.9418], device='cuda:7') Len  797\n",
      "Valid Loss True tensor([305.0657], device='cuda:7') Len  790\n",
      "Valid Loss True tensor([286.0165], device='cuda:7') Len  779\n",
      "Valid Loss True tensor([281.7462], device='cuda:7') Len  769\n",
      "Valid Loss True tensor([319.5873], device='cuda:7') Len  761\n",
      "Valid Loss True tensor([289.2447], device='cuda:7') Len  748\n",
      "Valid Loss True tensor([269.4591], device='cuda:7') Len  739\n",
      "Valid Loss True tensor([266.5046], device='cuda:7') Len  724\n",
      "Valid Loss True tensor([265.9939], device='cuda:7') Len  715\n",
      "Valid Loss True tensor([263.1206], device='cuda:7') Len  706\n",
      "Valid Loss True tensor([259.7787], device='cuda:7') Len  699\n",
      "Valid Loss True tensor([261.9029], device='cuda:7') Len  691\n",
      "Valid Loss True tensor([250.0756], device='cuda:7') Len  683\n",
      "Valid Loss True tensor([260.6797], device='cuda:7') Len  675\n",
      "Valid Loss True tensor([243.9441], device='cuda:7') Len  663\n",
      "Valid Loss True tensor([244.4959], device='cuda:7') Len  655\n",
      "Valid Loss True tensor([226.4660], device='cuda:7') Len  641\n",
      "Valid Loss True tensor([237.7060], device='cuda:7') Len  635\n",
      "Valid Loss True tensor([228.3041], device='cuda:7') Len  624\n",
      "Valid Loss True tensor([218.0809], device='cuda:7') Len  615\n",
      "Valid Loss True tensor([223.8835], device='cuda:7') Len  608\n",
      "Valid Loss True tensor([225.8325], device='cuda:7') Len  601\n",
      "Valid Loss True tensor([219.2275], device='cuda:7') Len  595\n",
      "Valid Loss True tensor([208.7199], device='cuda:7') Len  588\n",
      "Valid Loss True tensor([226.1610], device='cuda:7') Len  581\n",
      "Valid Loss True tensor([228.8899], device='cuda:7') Len  573\n",
      "Valid Loss True tensor([198.2557], device='cuda:7') Len  565\n",
      "Valid Loss True tensor([212.2119], device='cuda:7') Len  558\n",
      "Valid Loss True tensor([215.5869], device='cuda:7') Len  553\n",
      "Valid Loss True tensor([210.5364], device='cuda:7') Len  546\n",
      "Valid Loss True tensor([193.8076], device='cuda:7') Len  539\n",
      "Valid Loss True tensor([198.1410], device='cuda:7') Len  535\n",
      "Valid Loss True tensor([195.2771], device='cuda:7') Len  528\n",
      "Valid Loss True tensor([199.2168], device='cuda:7') Len  521\n",
      "Valid Loss True tensor([179.1343], device='cuda:7') Len  517\n",
      "Valid Loss True tensor([200.1542], device='cuda:7') Len  513\n",
      "Valid Loss True tensor([191.0676], device='cuda:7') Len  511\n",
      "Valid Loss True tensor([191.0501], device='cuda:7') Len  506\n",
      "Valid Loss True tensor([193.9987], device='cuda:7') Len  503\n",
      "Valid Loss True tensor([182.1830], device='cuda:7') Len  498\n",
      "Valid Loss True tensor([182.6420], device='cuda:7') Len  493\n",
      "Valid Loss True tensor([189.3301], device='cuda:7') Len  487\n",
      "Valid Loss True tensor([180.2073], device='cuda:7') Len  482\n",
      "Valid Loss True tensor([179.7247], device='cuda:7') Len  477\n",
      "Valid Loss True tensor([176.8545], device='cuda:7') Len  475\n",
      "Valid Loss True tensor([183.4758], device='cuda:7') Len  469\n",
      "Valid Loss True tensor([182.6383], device='cuda:7') Len  466\n",
      "Valid Loss True tensor([175.3380], device='cuda:7') Len  462\n",
      "Valid Loss True tensor([170.0243], device='cuda:7') Len  458\n",
      "Valid Loss True tensor([168.7243], device='cuda:7') Len  454\n",
      "Valid Loss True tensor([163.2639], device='cuda:7') Len  450\n",
      "Valid Loss True tensor([162.4341], device='cuda:7') Len  444\n",
      "Valid Loss True tensor([169.0798], device='cuda:7') Len  440\n",
      "Valid Loss True tensor([172.7528], device='cuda:7') Len  436\n",
      "Valid Loss True tensor([160.6879], device='cuda:7') Len  432\n",
      "Valid Loss True tensor([157.8681], device='cuda:7') Len  427\n",
      "Valid Loss True tensor([165.0744], device='cuda:7') Len  423\n",
      "Valid Loss True tensor([158.0670], device='cuda:7') Len  420\n",
      "Valid Loss True tensor([155.6542], device='cuda:7') Len  416\n",
      "Valid Loss True tensor([149.3503], device='cuda:7') Len  412\n",
      "Valid Loss True tensor([160.7120], device='cuda:7') Len  407\n",
      "Valid Loss True tensor([146.8497], device='cuda:7') Len  404\n",
      "Valid Loss True tensor([152.4063], device='cuda:7') Len  399\n",
      "Valid Loss True tensor([145.1820], device='cuda:7') Len  395\n",
      "Valid Loss True tensor([142.0280], device='cuda:7') Len  392\n",
      "Valid Loss True tensor([155.1430], device='cuda:7') Len  387\n",
      "Valid Loss True tensor([140.7486], device='cuda:7') Len  385\n",
      "Valid Loss True tensor([148.0081], device='cuda:7') Len  381\n",
      "Valid Loss True tensor([147.2485], device='cuda:7') Len  377\n",
      "Valid Loss True tensor([134.8593], device='cuda:7') Len  373\n",
      "Valid Loss True tensor([136.0146], device='cuda:7') Len  369\n",
      "Valid Loss True tensor([132.4745], device='cuda:7') Len  366\n",
      "Valid Loss True tensor([132.0184], device='cuda:7') Len  361\n",
      "Valid Loss True tensor([135.8045], device='cuda:7') Len  356\n",
      "Valid Loss True tensor([135.6484], device='cuda:7') Len  352\n",
      "Valid Loss True tensor([126.5300], device='cuda:7') Len  349\n",
      "Valid Loss True tensor([129.7804], device='cuda:7') Len  346\n",
      "Valid Loss True tensor([124.1985], device='cuda:7') Len  342\n",
      "Valid Loss True tensor([121.1923], device='cuda:7') Len  338\n"
     ]
    }
   ],
   "source": [
    "avg_len = 0\n",
    "model_latest.eval()\n",
    "for iiter, (utt_id, batch) in enumerate(data_loader_valid):\n",
    "    batch = to_device(batch, \"cuda:7\")\n",
    "    #print(iiter, utt_id, batch)\n",
    "    retval = model_latest(**batch)\n",
    "    print(\"Valid Loss True\", retval[0].data,  \"Len \", batch[\"speech\"].shape[1])\n",
    "        \n",
    "    if iiter == 100:\n",
    "        break\n",
    "    #avg_len += batch[\"speech\"].shape[1]\n",
    "#print(avg_len//len(data_loader_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b955b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "548ea3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([186.4736], device='cuda:6', grad_fn=<UnsqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model_ave_best.eval()\n",
    "batch = to_device(batch, \"cuda:6\")\n",
    "retval = model_ave_best(**batch)\n",
    "print(retval[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ce853c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([178.8518], device='cuda:6', grad_fn=<UnsqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model_ave_best.eval()\n",
    "batch = to_device(batch, \"cuda:6\")\n",
    "retval = model_ave_best(**batch)\n",
    "print(retval[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68193461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([186.4736], device='cuda:6', grad_fn=<UnsqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model_ave_best10.eval()\n",
    "batch = to_device(batch, \"cuda:6\")\n",
    "retval = model_ave_best10(**batch)\n",
    "print(retval[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7da009fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ba65b185",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = \"/data/common/LibriSpeech/train-clean-100-reduced\"\n",
    "\n",
    "all_paths = []\n",
    "for root, dirs, files in os.walk(d):\n",
    "    for f in files:\n",
    "        if \".txt\" in f:\n",
    "        #if \"flac\" in f:\n",
    "            p = f\"{root}/{f}\"\n",
    "            all_paths.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c3a37e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/common/LibriSpeech/train-clean-100-reduced/103/1240/103-1240.trans.txt',\n",
       " '/data/common/LibriSpeech/train-clean-100-reduced/103/1241/103-1241.trans.txt',\n",
       " '/data/common/LibriSpeech/train-clean-100-reduced/1034/121119/1034-121119.trans.txt',\n",
       " '/data/common/LibriSpeech/train-clean-100-reduced/1040/133433/1040-133433.trans.txt',\n",
       " '/data/common/LibriSpeech/train-clean-100-reduced/1069/133699/1069-133699.trans.txt']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f90d4a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(all_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4e5e16da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = all_paths[:-5000]\n",
    "dev_set = all_paths[-5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d451b612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23539"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "85b8b180",
   "metadata": {},
   "outputs": [],
   "source": [
    "dest = 'dev-from-train'\n",
    "ls_path = '/data/common/LibriSpeech'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c4ad24ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/common/LibriSpeech/train-clean-100-reduced/6476/57446/6476-57446-0062.wav',\n",
       " '/data/common/LibriSpeech/train-clean-100-reduced/226/122538/226-122538-0024.wav',\n",
       " '/data/common/LibriSpeech/train-clean-100-reduced/7226/86964/7226-86964-0054.wav',\n",
       " '/data/common/LibriSpeech/train-clean-100-reduced/3607/135982/3607-135982-0010.wav']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_set[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "be01c01c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File is not in dev set\n",
      "File is not in dev set\n",
      "File is not in dev set\n",
      "File is not in dev set\n"
     ]
    }
   ],
   "source": [
    "for f in all_paths:\n",
    "    s = f.split('/')[-3:]\n",
    "    spk, chapter, fname = s\n",
    "    dest_path = f\"{ls_path}/{dest}/{spk}/{chapter}/\"\n",
    "    #if not os.path.exists(dest_path):\n",
    "    #    os.makedirs(dest_path)\n",
    "    #shutil.move(f, dest_path)\n",
    "    #print(dest_path)\n",
    "    source_path = f\"{d}/{spk}/{chapter}/{spk}-{chapter}.trans.txt\"\n",
    "    #print(source_path, dest_path)\n",
    "    try:\n",
    "        shutil.copy(source_path, dest_path)\n",
    "    except FileNotFoundError:\n",
    "        print(\"File is not in dev set\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd3953c7-81fe-4e49-b444-0c862ecf695e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dac\n",
    "from audiotools import AudioSignal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26885deb-e71a-41d5-abf1-5457062624ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anakuzne/espnet/tools/enc_asr/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DAC(\n",
       "  (encoder): Encoder(\n",
       "    (block): Sequential(\n",
       "      (0): Conv1d(1, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "      (1): EncoderBlock(\n",
       "        (block): Sequential(\n",
       "          (0): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (2): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (3): Snake1d()\n",
       "          (4): Conv1d(64, 128, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "        )\n",
       "      )\n",
       "      (2): EncoderBlock(\n",
       "        (block): Sequential(\n",
       "          (0): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (2): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (3): Snake1d()\n",
       "          (4): Conv1d(128, 256, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "        )\n",
       "      )\n",
       "      (3): EncoderBlock(\n",
       "        (block): Sequential(\n",
       "          (0): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (2): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (3): Snake1d()\n",
       "          (4): Conv1d(256, 512, kernel_size=(10,), stride=(5,), padding=(3,))\n",
       "        )\n",
       "      )\n",
       "      (4): EncoderBlock(\n",
       "        (block): Sequential(\n",
       "          (0): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (2): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (3): Snake1d()\n",
       "          (4): Conv1d(512, 1024, kernel_size=(16,), stride=(8,), padding=(4,))\n",
       "        )\n",
       "      )\n",
       "      (5): Snake1d()\n",
       "      (6): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    )\n",
       "  )\n",
       "  (quantizer): ResidualVectorQuantize(\n",
       "    (quantizers): ModuleList(\n",
       "      (0-11): 12 x VectorQuantize(\n",
       "        (in_proj): Conv1d(1024, 8, kernel_size=(1,), stride=(1,))\n",
       "        (out_proj): Conv1d(8, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (codebook): Embedding(1024, 8)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (model): Sequential(\n",
       "      (0): Conv1d(1024, 1536, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "      (1): DecoderBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Snake1d()\n",
       "          (1): ConvTranspose1d(1536, 768, kernel_size=(16,), stride=(8,), padding=(4,))\n",
       "          (2): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (3): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (4): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Snake1d()\n",
       "          (1): ConvTranspose1d(768, 384, kernel_size=(10,), stride=(5,), padding=(3,))\n",
       "          (2): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (3): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (4): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Snake1d()\n",
       "          (1): ConvTranspose1d(384, 192, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "          (2): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (3): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (4): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Snake1d()\n",
       "          (1): ConvTranspose1d(192, 96, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "          (2): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (3): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (4): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): Snake1d()\n",
       "      (6): Conv1d(96, 1, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "      (7): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = dac.utils.download(model_type=\"16khz\")\n",
    "model = dac.DAC.load(model_path)\n",
    "\n",
    "model.to('cuda:5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "102de1a5-9983-4e0f-9eff-bb80f4a4cc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load audio signal file\n",
    "signal = AudioSignal('/data/anakuzne/LibriSpeech/train-clean-100/201/122255/201-122255-0000.wav')\n",
    "\n",
    "# Encode audio signal as one long file\n",
    "# (may run out of GPU memory on long files)\n",
    "signal.to(model.device)\n",
    "\n",
    "x = model.preprocess(signal.audio_data, signal.sample_rate)\n",
    "z, codes, latents, _, _ = model.encode(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aac95b8-691c-48e3-a466-c2362cb7f2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5aa996db-1b30-4d12-aee1-a1f43b05d551",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantizer = model.quantizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d235af1-e7de-4f75-864a-36d2d6d5901e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResidualVectorQuantize(\n",
      "  (quantizers): ModuleList(\n",
      "    (0-11): 12 x VectorQuantize(\n",
      "      (in_proj): Conv1d(1024, 8, kernel_size=(1,), stride=(1,))\n",
      "      (out_proj): Conv1d(8, 1024, kernel_size=(1,), stride=(1,))\n",
      "      (codebook): Embedding(1024, 8)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(quantizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f5946aa-da1d-4233-baad-501cc8210ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = encoder(signal.audio_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de5d5afa-9775-4f8f-a47f-72e9bff57d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024, 246])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e71506aa-288f-477b-a0f6-987e02e20c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0004,  0.0003, -0.0003,  ...,  0.0024, -0.0024,  0.0013]]],\n",
       "       device='cuda:5')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal.audio_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cc896c-1a74-4c5c-996f-4af5c441315e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
